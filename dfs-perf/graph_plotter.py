# -*- coding: utf-8 -*-
"""Graph_plotter.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-gmSifGPUbC0bGqtHWSNL9mvYhkQFEfs
"""

# Commented out IPython magic to ensure Python compatibility.
### NOTE: 
### Please upload the simple_read_cloudlab.csv file on the left before running the cells in the notebook!

# %matplotlib inline

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import sys

def generate_timestamp(data):
    # normalize timestamp to seconds
    time_start = data['StartTime'].astype('float64').min()
    data['StartTimeIndex'] = (data['StartTime'].astype('float64') - time_start) // 1000
    data['EndTimeIndex'] = (data['EndTime'].astype('float64') - time_start) // 1000 + 1

def process(data):
    # build data in seconds
    time_indices = np.arange(data['EndTimeIndex'].max() + 1)
    num_bytes = np.zeros_like(time_indices, dtype=np.float64)
    latencies = np.zeros_like(time_indices, dtype=np.float64)
    counts = np.zeros_like(time_indices, dtype=np.float64)

    for _, row in data.iterrows():
        start = int(row['StartTimeIndex'])
        end = int(row['EndTimeIndex'])
        num_bytes[start:end] += row['NumBytes'] / float(end - start)
        latencies[start:end] += row['Duration']
        counts[start:end] += 1

    counts = counts.clip(min=1, max=None)  # avoid divide by zero
    latencies = latencies / counts         # average latency
    throughputs = num_bytes / 1024 / 1024  # convert to MB/sec
    
    return time_indices, throughputs, latencies

def plot_events(events):    
    for (x, y, offset), label in events:
        plt.axvline(x=x, color='r', linestyle='--')
        plt.text(x=(x+offset), y=y, s=label)


def plot_subplot(x, y, xlabel, ylabel, title, events):
    plt.title(title)
    plt.plot(x, y)
    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    plt.ylim(bottom=0)
    plot_events(events)

# load data
if __name__=="__main__":
    csv_file = sys.argv[1]
    baseline_call = pd.read_csv(csv_file)
    generate_timestamp(baseline_call)
    baseline_call = baseline_call[:40000]
    # file level statistics
    call_stat = {}
    time_indices, throughputs, latencies = process(baseline_call)
    call_stat['baseline'] = {
        'time_indices': time_indices,
        'throughputs': throughputs,
        'latencies': latencies
    }
    # truncate, only keep data from 30 s to 20 min
    data = {
        'baseline': {
            'time_indices': call_stat['baseline']['time_indices'][30:20*60] - 30,
            'throughputs': call_stat['baseline']['throughputs'][30:20*60],
            'latencies': call_stat['baseline']['latencies'][30:20*60]        
        }
    }
    # throughput
    xlabel = 'Time (sec)'
    ylabel = 'Throughput (MB/sec)'
    yoffset = 1000
        
    plt.figure(figsize=(19.2,4.8))
            
    plt.subplot(131)
    plot_subplot(data['baseline']['time_indices'], data['baseline']['throughputs'], 
                xlabel, ylabel, 'Baseline', [])
        
    plt.show()
    plt.savefig('throughput_graph.png')    
    # latency
    ylabel = 'Latency (millisecond)'
    yoffset = 150
        
    plt.figure(figsize=(19.2,4.8))
            
    plt.subplot(131)
    plot_subplot(data['baseline']['time_indices'], data['baseline']['latencies'], 
                xlabel, ylabel, 'Baseline', [])
        
    plt.show()
    plt.savefig('latency_graph.png')
